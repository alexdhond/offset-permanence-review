---
title: "Permanence Risks Analysis"
author: "Alex Dhond"
project:
  type: default
  output-dir: output
format:
  html:
    self-contained: true
---

# Offset Permanence Review Data Exploration

Here I explore my data set and the patterns in permanence risks across biodiversity and carbon offset programs, policies, temporal trends, geography, project types, ecosystem types, and other core variables.

------------------------------------------------------------------------

## 1. Setup

### 1.1. Load Required Packages

```{r}
#| label: load-packages
#| include: false

# Load all packages 
library(tidyverse) # Data manipulation
library(here) # Easy file paths
library(janitor) # Clean column names
library(readxl) # Reading Excel files
library(countrycode) # Geospatial countries
library(sf) # Geospatial data
library(rnaturalearth) # Geospatial data
library(rnaturalearthdata) # Geospatial data
library(RColorBrewer) # Plot colors
library(knitr) # Knitting document
library(gt) # Tables
library(purrr) # Dataframe manipulation
library(RColorBrewer) # table colors
library(viridis) # colors
library(scales) # colors
library(glue) # output
library(colorspace) # figures

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

### 1.2. Load Helper Functions

```{r}
#| label: load-functions
#| include: false

# Count unique studies mentioning each variable value
summarize_by_study <- function(data, var, label = NULL) {
  var <- rlang::enquo(var)
  label <- label %||% rlang::as_name(var)

  data %>%
    filter(!is.na(!!var), !!var != "") %>%
    group_by(!!var) %>%
    summarise(n_studies = n_distinct(study_id), .groups = "drop") %>%
    arrange(desc(n_studies)) %>%
    rename(!!label := !!var)
}

# Format a gt summary table from summarize_by_study() output

make_summary_table <- function(df, var_name, table_title) {
  df %>%
    gt() %>%
    tab_header(title = md(paste0("**", table_title, "**"))) %>%
    cols_label(
      !!var_name := "Category",
      n_studies = "Number of Studies"
    ) %>%
    fmt_number(columns = "n_studies", decimals = 0) %>%
    tab_style(
      style = cell_text(weight = "bold"),
      locations = cells_column_labels(everything())
    ) %>%
    tab_options(
      table.width = "90%",
      table.border.top.style = "solid",
      table.border.top.width = px(1),
      table.border.top.color = "black",
      table.border.bottom.style = "solid",
      table.border.bottom.width = px(1),
      table.border.bottom.color = "black",
      table.border.left.style = "solid",
      table.border.left.width = px(1),
      table.border.left.color = "black",
      table.border.right.style = "solid",
      table.border.right.width = px(1),
      table.border.right.color = "black"
    )
}

# Safe combo generator
get_combos <- function(risk_list, combo_size = 2) {
  if (length(risk_list) >= combo_size) {
    combn(risk_list, combo_size, simplify = FALSE)
  } else {
    list()
  }
}

# Count studies with non-missing values
studies_reporting <- function(var) {
  final_df %>%
    filter(!is.na({{ var }})) %>%
    distinct(study_id) %>% 
    nrow()
}
```

### 1.3. Load Data

```{r}
#| label: load-data
#| include: false

# Load the cleaned, long, final dataset
final_df <- read_csv(
  here("data", "derived", "offset_perm_rev_long_cleaned.csv"),
  guess_max = 10000,
  col_types = cols(
    species_common_name     = col_character(),
    species_scientific_name = col_character(),
    species_taxonomic_group = col_character(),
    .default = col_guess()
  )
)

# Ensure every study_title has a unique study_id
final_df <- final_df %>%
  mutate(study_id = paste0("id_", as.integer(factor(study_title))))

# Load risk typology
risk_typology <- read_csv(here("data", "reference", "permanence_risk_typology_lookup.csv")) %>%
  janitor::clean_names() %>%
  select(domain = broad, category = specific, type = sub_risk)

# Count total unique studies in dataset
total_unique_studies <- final_df %>%
  distinct(study_id) %>%
  nrow()
```


------------------------------------------------------------------------

## 2. Database Overview

Here I summarize the key characteristics of the final dataset, including ecosystem types, programs, policies, and evidence types.

### 2.1. Key Dataset Statistics

Print basic tables that show the number of studies per category.

```{r}
#| label: key-data-stats
#| echo: false

# Generate summaries
offset_summary    <- summarize_by_study(final_df, offset_category_general)
evidence_summary  <- summarize_by_study(final_df, study_evidence_type)
continent_summary <- summarize_by_study(final_df, continent)

# Only showing top 10 countries
country_summary <- summarize_by_study(final_df, country) %>%
  dplyr::slice_max(order_by = n_studies, n = 10, with_ties = FALSE)

ecosystem_summary <- summarize_by_study(final_df, ecosystem_broad_type)

# Only showing top 10 species
species_summary <- summarize_by_study(final_df, species_common_name) %>%
  dplyr::slice_max(order_by = n_studies, n = 10, with_ties = FALSE)

eco_act_summary   <- summarize_by_study(final_df, project_broad_type)

# Only showing top 10 programs
program_summary <- summarize_by_study(final_df, program_name) %>%
  dplyr::slice_max(order_by = n_studies, n = 10, with_ties = FALSE)

# Only showing top 10 policies
policy_summary <- summarize_by_study(final_df, policy_name) %>%
  dplyr::slice_max(order_by = n_studies, n = 10, with_ties = FALSE)
```

::: {.layout-ncol=2}
```{r}
#| label: data-stats-offset-summary
#| echo: false
make_summary_table(offset_summary, "offset_category_general", "Offset Types")
```

```{r}
#| label: data-stats-evidence-summary
#| echo: false
make_summary_table(evidence_summary, "study_evidence_type", "Evidence Types")
```
:::
::: {.layout-ncol=2}
```{r}
#| label: data-stats-continent-summary
#| echo: false
make_summary_table(continent_summary, "continent", "Continents")
```

```{r}
#| label: data-stats-country-summary
#| echo: false
make_summary_table(country_summary, "country", "Countries (Top 10)")
```
:::
::: {.layout-ncol=2}
```{r}
#| label: data-stats-ecosystem-summary
#| echo: false
make_summary_table(ecosystem_summary, "ecosystem_broad_type", "Ecosystem Types (Broad)")
```

```{r}
#| label: data-stats-species-summary
#| echo: false
make_summary_table(species_summary, "species_common_name", "Focal Species (Top 10)")
```
:::
::: {.layout-ncol=2}
```{r}
#| label: data-stats-program-summary
#| echo: false
make_summary_table(program_summary, "program_name", "Offset Programs (Top 10)")
```

```{r}
#| label: data-stats-policy-summary
#| echo: false
make_summary_table(policy_summary, "policy_name", "Policies (Top 10)")
```
:::
```{r}
#| label: eco-act-summary
#| echo: false
make_summary_table(eco_act_summary, "project_broad_type", "Ecological Action Types")
```

### 2.1.1. Table: Key Dataset Statistics

This table provides an overview of major variables captured in the final dataset, including study characteristics, offset types, ecosystem focus, program and policy mentions, and classifications of permanence risks. For each variable, the table shows the number of unique values observed, how many studies mention the variable, the percentage of total studies, and the top three most frequently cited values (with study counts).

```{r}
#| label: data-summary-table
#| echo: false

# Calculate total unique studies
# Use study_id for total count too:
total_studies <- final_df %>%
  distinct(study_id) %>%
  nrow()

# Helper function
summarize_variable <- function(df, var, label, top_n = 3, linebreak = "html") {
  df_clean <- df %>%
    filter(!is.na(.data[[var]]), .data[[var]] != "") %>%
    group_by(study_id) %>%
    summarise(values = list(unique(.data[[var]])), .groups = "drop")

  study_count <- nrow(df_clean)
  all_vals <- unlist(df_clean$values)
  val_counts <- sort(table(all_vals), decreasing = TRUE)
  unique_vals <- length(unique(all_vals))
  top_vals <- head(val_counts, top_n)

  sep <- dplyr::case_when(
    linebreak == "html" ~ "<br>",
    linebreak == "newline" ~ "\n",
    TRUE ~ "; "
  )

  top_vals_text <- paste0(names(top_vals), " (n = ", top_vals, ")", collapse = sep)

  tibble(
    Variable = label,
    `Unique Values` = unique_vals,
    `Studies Mentioning` = study_count,
    `% of Total` = paste0(round(100 * study_count / total_studies), "%"),
    `Top 3 Values (N)` = top_vals_text
  )
}

# Variable names and desired row order
var_list <- list(
  c("study_publication_year", "Publication Year"),
  c("offset_category_general", "Offset Type"),
  c("study_evidence_type", "Evidence Type"),
  c("country", "Country"),
  c("ecosystem_broad_type", "Ecosystem (Broad)"),
  c("species_common_name", "Focal Species"),
  c("project_broad_type", "Project Type"),
  c("program_name", "Offset Programs"),
  c("policy_name", "Policies"),
  c("permanence_risk_domain", "Permanence Risk Domains"),
  c("permanence_risk_category", "Permanence Risk Categories"),
  c("permanence_risk_type", "Permanence Risk Types")
)

desired_order <- sapply(var_list, function(x) x[2])

# Generate both versions (HTML and CSV-friendly)
summary_html <- bind_rows(lapply(var_list, function(x) {
  summarize_variable(final_df, var = x[1], label = x[2], linebreak = "html")
})) %>%
  mutate(Variable = factor(Variable, levels = desired_order)) %>%
  arrange(Variable)

summary_csv <- bind_rows(lapply(var_list, function(x) {
  summarize_variable(final_df, var = x[1], label = x[2], linebreak = "newline")
})) %>%
  mutate(Variable = factor(Variable, levels = desired_order)) %>%
  arrange(Variable)

# Display table in Quarto document
summary_html %>%
  gt() %>%
  tab_header(title = "Key Dataset Variables") %>%
  cols_label(
    `Unique Values` = "Unique Values",
    `Studies Mentioning` = "Studies Mentioning",
    `% of Total` = "% of Total",
    `Top 3 Values (N)` = "Top 3 Values (n)"
  ) %>%
  fmt_markdown(columns = vars(`Top 3 Values (N)`))

# Export CSV version to file
write.csv(summary_csv,
          file = here::here("output", "figures", "dataset_sum_table.csv"),
          row.names = FALSE)
```

### 2.2. Temporal Overview
Here I examine the distribution of study publication years over the dataset. Many of the studies included were published within the past 5-10 years.
```{r}
#| label: temporal-overview
#| echo: false
#| fig-width: 8
#| fig-height: 4

# Prepare data
year_summary <- final_df %>%
  filter(!is.na(study_publication_year)) %>%
  distinct(study_id, study_publication_year) %>%
  count(study_publication_year, name = "n_studies") %>%
  arrange(study_publication_year)


# Plot bar chart
ggplot(year_summary, aes(x = study_publication_year, y = n_studies)) +
  geom_col(fill = "#69b3a2", color = "black") +
  geom_text(aes(label = n_studies), vjust = -0.3, size = 3) +
  scale_x_continuous(breaks = seq(min(year_summary$study_publication_year, na.rm = TRUE),
                                   max(year_summary$study_publication_year, na.rm = TRUE), 
                                   by = 2)) +
  labs(
    title = "Number of Studies Published per Year",
    x = "Publication Year",
    y = "Number of Studies"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid.major.x = element_blank()
  )
```

------------------------------------------------------------------------

## 3. Study Characteristics by Offset Category

Let's break down how the key supporting variables differ between **biodiversity** and **carbon** offset studies. For reference, the key variables are:

-   Evidence Type

-   Continent/Country

-   Ecosystem

-   Focal Species

-   Project Type

-   Offset Program

-   Offset Policy

Each figure below shows the number of studies referencing a given value, grouped by offset type.

------------------------------------------------------------------------

### 3.1. Evidence Type x Offset Category

Here I dive into how the evidence types break down across biodiversity and carbon offset studies. Each study was assigned to one of the following evidence types:

1.  Direct Empirical Studies: These assessed permanence risks through primary data collection, either by observing and documenting realized risks (e.g., offset site degradation), or empirically measuring conditions associated with permanence risks (e.g., encroachment, fire frequency). This included field-based assessments, project compliance evaluations, case study analysis, and single- or multi-project site examinations.

2.  Modelling Studies: These evaluated permanence risks using quantitative modelling or simulations rather than direct field observation.

3.  Review and Discussion-based Studies: These synthesized multiple sources to examine permanence risks more broadly and often incorporated both empirical evidence and theoretical insights.

4.  Conceptual, Legal, and Policy-focused Studies: These explored permanence risks from governance, legal, policy, or theoretical perspectives, typically identifying risks through logical reasoning or policy analyses rather than empirical observation .

The table and bar charts below give counts of how many studies fall into each category for each offset type. 
```{r}
#| label: evidence-type-offset-category-table
#| echo: false

# Create summary table
evidence_offset_summary <- final_df %>%
  filter(
    !is.na(study_evidence_type), study_evidence_type != "",
    !is.na(offset_category_general), offset_category_general != ""
  ) %>%
  group_by(study_evidence_type, offset_category_general) %>%
  summarise(n_studies = n_distinct(study_id), .groups = "drop") %>%
  pivot_wider(names_from = offset_category_general, values_from = n_studies, values_fill = 0) %>%
  mutate(Total = biodiversity + carbon) %>%
  arrange(desc(Total))

# Display table
evidence_offset_summary %>%
  gt() %>%
  tab_header(title = md("**Evidence Types by Offset Category**")) %>%
  cols_label(
    study_evidence_type = "Evidence Type",
    biodiversity = "Biodiversity",
    carbon = "Carbon",
    Total = "Total"
  ) %>%
  fmt_number(columns = c(biodiversity, carbon, Total), decimals = 0) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(everything())
  )

```

```{r}
#| label: evidence-type-offset-category-plot
#| echo: false

# Prepare data for plot
evidence_offset_plot <- final_df %>%
  filter(
    !is.na(study_evidence_type), study_evidence_type != "",
    !is.na(offset_category_general), offset_category_general != ""
  ) %>%
  group_by(study_evidence_type, offset_category_general) %>%
  summarise(n_studies = n_distinct(study_id), .groups = "drop")

# Plot
ggplot(evidence_offset_plot,
       aes(x = fct_reorder(study_evidence_type, n_studies, .fun = sum),
           y = n_studies, fill = offset_category_general)) +
  geom_col(position = "dodge", color = "black") +
  geom_text(aes(label = n_studies),
            position = position_dodge(width = 0.9),
            hjust = -0.4, size = 4, color = "black") +
  scale_fill_brewer(palette = "Pastel1") +
  labs(
    title = "# Studies by Evidence Type and Offset Category",
    x = "Evidence Type",
    y = "Number of Studies",
    fill = "Offset Category"
  ) +
  coord_flip() +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top",
    plot.margin = margin(1, 1.5, 1, 1, unit = "lines")
  )

```
The most common evidence type was **`r evidence_offset_summary$study_evidence_type[1]`**
(`r evidence_offset_summary$Total[1]` total studies), with
`r evidence_offset_summary$biodiversity[1]` focused on biodiversity offsets and
`r evidence_offset_summary$carbon[1]` on carbon offsets.

This was followed by **`r evidence_offset_summary$study_evidence_type[2]`**
(`r evidence_offset_summary$Total[2]` studies), then
**`r evidence_offset_summary$study_evidence_type[3]`**
(`r evidence_offset_summary$Total[3]`), and
**`r evidence_offset_summary$study_evidence_type[4]`**
(`r evidence_offset_summary$Total[4]`).

Across all evidence types, the highest number of studies in a single offset category was for
**biodiversity-focused** **`r evidence_offset_summary$study_evidence_type[1]`**
studies (`r evidence_offset_summary$biodiversity[1]` studies).

------------------------------------------------------------------------

### 3.2. Geography x Offset Category

There were `r length(unique(final_df$country[!is.na(final_df$country)]))` total countries and `r length(unique(final_df$continent[!is.na(final_df$continent)]))` continents represented across the `r total_unique_studies` studies. Some studies, like reviews, policy discussions, or conceptual studies, covered multiple countries or continents.

To reflect this, I show the geographic distribution in two ways:

- The **table** below includes studies **as many times as they mention a country** (i.e., if a study referenced two countries, it appears in both). This means totals may exceed 137.
- The **bar chart** below counts each study **only once per continent**, which avoids double-counting.

```{r}
#| label: geography-offset-category
#| echo: false

# Total number of unique studies
total_unique_studies <- final_df %>%
  distinct(study_id) %>%
  nrow()

# Step 1: Create summary table (studies counted multiple times if in multiple countries)
country_data <- final_df %>%
  filter(!is.na(study_id), !is.na(country), !is.na(continent), !is.na(offset_category_general)) %>%
  distinct(study_id, continent, country, offset_category_general) %>%
  count(continent, country, offset_category_general) %>%
  pivot_wider(names_from = offset_category_general, values_from = n, values_fill = 0) %>%
  mutate(
    Total = biodiversity + carbon,
    is_total = FALSE
  )

# Step 2: Add continent totals for the table
continent_data <- country_data %>%
  group_by(continent) %>%
  summarise(
    biodiversity = sum(biodiversity),
    carbon = sum(carbon),
    Total = sum(Total),
    .groups = "drop"
  ) %>%
  mutate(
    country = "Continent Total",
    is_total = TRUE
  )

# Step 3: Combine for table
full_table <- bind_rows(country_data, continent_data) %>%
  arrange(continent, is_total, desc(Total))

# Step 4: Show table
full_table %>%
  gt(rowname_col = "country", groupname_col = "continent") %>%
  tab_header(title = md("**Study Counts by Continent, Country, and Offset Category**")) %>%
  cols_label(
    biodiversity = "Biodiversity",
    carbon = "Carbon",
    Total = "Total"
  ) %>%
  fmt_number(columns = c(biodiversity, carbon, Total), decimals = 0) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = list(
      cells_body(rows = is_total),
      cells_row_groups()
    )
  ) %>%
  cols_hide(columns = is_total) %>%
  cols_width(everything() ~ px(170)) %>%
  tab_options(data_row.padding = px(3))

# Step 5: Unique study per continent
continent_offset_plot <- final_df %>%
  filter(!is.na(study_id), !is.na(continent), !is.na(offset_category_general)) %>%
  distinct(study_id, continent, offset_category_general) %>%
  count(continent, offset_category_general, name = "n_studies")
# Step 6: Pivot wider for inline prose and plotting
continent_summary_clean <- continent_offset_plot %>%
  pivot_wider(names_from = offset_category_general, values_from = n_studies, values_fill = 0) %>%
  mutate(Total = biodiversity + carbon)

# Step 7: Plot
ggplot(continent_offset_plot,
       aes(x = fct_reorder(continent, n_studies, .fun = sum),
           y = n_studies,
           fill = offset_category_general)) +
  geom_col(position = position_dodge(width = 0.9), color = "black") +
  geom_text(aes(label = n_studies),
            position = position_dodge(width = 0.9),
            hjust = -0.4, size = 4, color = "black") +
  scale_fill_brewer(palette = "Pastel1") +
  labs(
    title = "# Studies by Continent and Offset Category",
    x = "Continent",
    y = "Number of Studies",
    fill = "Offset Category"
  ) +
  coord_flip() +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top",
    plot.margin = margin(1, 1.5, 1, 1, unit = "lines")
  )
```

A total of `r total_unique_studies` unique studies were included across `r length(unique(final_df$continent[!is.na(final_df$continent)]))` continents. The continent with the most studies overall was **`r continent_summary_clean$continent[which.max(continent_summary_clean$Total)]`**, with `r max(continent_summary_clean$Total)` studies.

**Biodiversity offset studies** were most common in:

1. `r continent_summary_clean$continent[order(-continent_summary_clean$biodiversity)][1]` (`r sort(continent_summary_clean$biodiversity, decreasing = TRUE)[1]`),
2. `r continent_summary_clean$continent[order(-continent_summary_clean$biodiversity)][2]` (`r sort(continent_summary_clean$biodiversity, decreasing = TRUE)[2]`),
3. `r continent_summary_clean$continent[order(-continent_summary_clean$biodiversity)][3]` (`r sort(continent_summary_clean$biodiversity, decreasing = TRUE)[3]`).


**Carbon offset studies** were most common in:

1. `r continent_summary_clean$continent[order(-continent_summary_clean$carbon)][1]` (`r sort(continent_summary_clean$carbon, decreasing = TRUE)[1]`),
2. `r continent_summary_clean$continent[order(-continent_summary_clean$carbon)][2]` (`r sort(continent_summary_clean$carbon, decreasing = TRUE)[2]`),
3. `r continent_summary_clean$continent[order(-continent_summary_clean$carbon)][3]` (`r sort(continent_summary_clean$carbon, decreasing = TRUE)[3]`).

**Biodiversity offset studies were more common than carbon offset studies** in:

- `r paste(continent_summary_clean$continent[continent_summary_clean$biodiversity > continent_summary_clean$carbon], collapse = ", ")`.

However, **carbon offset studies were more common than biodiversity offset studies** in:

- `r paste(continent_summary_clean$continent[continent_summary_clean$carbon > continent_summary_clean$biodiversity], collapse = ", ")`.

------------------------------------------------------------------------

### 3.3. Ecosystem Type x Offset Category

Here I explore the types of ecosystems represented. I extracted information from the specific ecosystem type mentioned by the authors (ecosystem_type) and then grouped that into several broad categories (ecosystem_broad_type).

In all, there were `r length(unique(final_df$ecosystem_type[!is.na(final_df$ecosystem_type)]))` specific ecosystem descriptions mentioned across the studies, which I grouped into `r length(unique(final_df$ecosystem_broad_type[!is.na(final_df$ecosystem_broad_type)]))` different ecosystem types across the `r total_unique_studies` studies. Like with geographic regions, some studies referenced multiple ecosystems.

```{r}
#| label: ecosystem-offset-category
#| echo: false

# Summarize ecosystem by offset category
ecosystem_offset_summary <- final_df %>%
  filter(!is.na(ecosystem_broad_type), !is.na(offset_category_general)) %>%
  distinct(study_id, ecosystem_broad_type, offset_category_general) %>%
  count(ecosystem_broad_type, offset_category_general) %>%
  pivot_wider(names_from = offset_category_general, values_from = n, values_fill = 0) %>%
  mutate(Total = biodiversity + carbon) %>%
  arrange(desc(Total))

# Extract values
top_ecosystem <- ecosystem_offset_summary$ecosystem_broad_type[1]
top_ecosystem_total <- ecosystem_offset_summary$Total[1]
forest_bio <- ecosystem_offset_summary$biodiversity[ecosystem_offset_summary$ecosystem_broad_type == "Forest"]
forest_carbon <- ecosystem_offset_summary$carbon[ecosystem_offset_summary$ecosystem_broad_type == "Forest"]

# Step 1: Prepare data for the table
ecosystem_summary_table <- final_df %>%
  filter(!is.na(study_id), !is.na(ecosystem_broad_type), !is.na(offset_category_general)) %>%
  distinct(study_id, ecosystem_broad_type, offset_category_general) %>%
  count(ecosystem_broad_type, offset_category_general, name = "n_studies") %>%
  pivot_wider(
    names_from = offset_category_general,
    values_from = n_studies,
    values_fill = 0
  ) %>%
  mutate(Total = biodiversity + carbon) %>%
  arrange(desc(Total))

# Step 2: Display table using gt
ecosystem_summary_table %>%
  gt() %>%
  tab_header(title = md("**Study Counts by Ecosystem Type and Offset Category**")) %>%
  cols_label(
    ecosystem_broad_type = "Ecosystem Type",
    biodiversity = "Biodiversity",
    carbon = "Carbon",
    Total = "Total"
  ) %>%
  fmt_number(columns = c(biodiversity, carbon, Total), decimals = 0) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(everything())
  ) %>%
  cols_width(everything() ~ px(150)) %>%
  tab_options(data_row.padding = px(4))


# Step 3: Prepare data for the bar plot
ecosystem_offset_plot <- final_df %>%
  filter(
    !is.na(study_title),
    !is.na(ecosystem_broad_type),
    !is.na(offset_category_general)
  ) %>%
  distinct(study_title, ecosystem_broad_type, offset_category_general) %>%
  count(ecosystem_broad_type, offset_category_general, name = "n_studies")

# Step 4: Plot
ggplot(ecosystem_offset_plot,
       aes(x = fct_reorder(ecosystem_broad_type, n_studies, .fun = sum),
           y = n_studies,
           fill = offset_category_general)) +
  geom_col(position = position_dodge(width = 0.9), color = "black") +
  geom_text(aes(label = n_studies),
            position = position_dodge(width = 0.9),
            hjust = -0.4, size = 4, color = "black") +
  scale_fill_brewer(palette = "Pastel1") +
  labs(
    title = "# Studies by Ecosystem Type and Offset Category",
    x = "Ecosystem Type",
    y = "Number of Studies",
    fill = "Offset Category"
  ) +
  coord_flip() +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top",
    plot.margin = margin(1, 1.5, 1, 1, unit = "lines")
  )
```
The most commonly discussed ecosystem across all studies was **`r ecosystem_offset_summary$ecosystem_broad_type[1]`**, with a total of **`r ecosystem_offset_summary$Total[1]`** studies. Of those, **`r ecosystem_offset_summary$biodiversity[1]`** focused on biodiversity offsets and **`r ecosystem_offset_summary$carbon[1]`** on carbon offsets.

Biodiversity offset studies frequently examined the following ecosystems:
- **`r ecosystem_offset_summary$ecosystem_broad_type[ecosystem_offset_summary$biodiversity == max(ecosystem_offset_summary$biodiversity, na.rm = TRUE)][1]`** (`r max(ecosystem_offset_summary$biodiversity, na.rm = TRUE)` studies),
- **`r ecosystem_offset_summary$ecosystem_broad_type[order(-ecosystem_offset_summary$biodiversity)][2]`** (`r ecosystem_offset_summary$biodiversity[order(-ecosystem_offset_summary$biodiversity)][2]` studies), and
- **`r ecosystem_offset_summary$ecosystem_broad_type[order(-ecosystem_offset_summary$biodiversity)][3]`** (`r ecosystem_offset_summary$biodiversity[order(-ecosystem_offset_summary$biodiversity)][3]` studies).

In contrast, carbon offset studies were heavily focused on **`r ecosystem_offset_summary$ecosystem_broad_type[which.max(ecosystem_offset_summary$carbon)]`** ecosystems, with **`r max(ecosystem_offset_summary$carbon)`** studies.

------------------------------------------------------------------------

### 3.4. Ecological Action Type x Offset Category
Where possible, I extracted what specific ecological actions the study focused on. For example, offsets that either focused on restoration, creation, enhancement, or protection. These were grouped into 8 broad categories.
```{r}
#| label: ecoaction-offset-category
#| echo: false

# Total unique studies
total_unique_studies <- final_df %>%
  distinct(study_title) %>%
  nrow()

# Step 1: Create summary table (study can appear in multiple actions, but not duplicated)
ecoact_summary_table <- final_df %>%
  filter(!is.na(study_id), !is.na(project_broad_type), !is.na(offset_category_general)) %>%
  distinct(study_id, project_broad_type, offset_category_general) %>%
  count(project_broad_type, offset_category_general, name = "n_studies") %>%
  pivot_wider(names_from = offset_category_general, values_from = n_studies, values_fill = 0) %>%
  mutate(Total = biodiversity + carbon) %>%
  arrange(desc(Total))


# Extract values for prose
top1_type <- ecoact_summary_table$project_broad_type[1]
top1_total <- ecoact_summary_table$Total[1]

top2_type <- ecoact_summary_table$project_broad_type[2]
top2_total <- ecoact_summary_table$Total[2]

top3_type <- ecoact_summary_table$project_broad_type[3]
top3_total <- ecoact_summary_table$Total[3]

top_carbon_type <- ecoact_summary_table$project_broad_type[which.max(ecoact_summary_table$carbon)]
top_carbon_n <- max(ecoact_summary_table$carbon)

top_biodiversity_type <- ecoact_summary_table$project_broad_type[which.max(ecoact_summary_table$biodiversity)]
top_biodiversity_n <- max(ecoact_summary_table$biodiversity)

# Step 2: Show table
ecoact_summary_table %>%
  gt() %>%
  tab_header(title = md("**Study Counts by Ecological Action Type and Offset Category**")) %>%
  cols_label(
    project_broad_type = "Ecological Action Type",
    biodiversity = "Biodiversity",
    carbon = "Carbon",
    Total = "Total"
  ) %>%
  fmt_number(columns = c(biodiversity, carbon, Total), decimals = 0) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(everything())
  ) %>%
  cols_width(everything() ~ px(200)) %>%
  tab_options(data_row.padding = px(3))

# Step 3: Prepare plot data (study counted once per action-category pair)
ecoact_plot_data <- final_df %>%
  filter(!is.na(study_id), !is.na(project_broad_type), !is.na(offset_category_general)) %>%
  distinct(study_id, project_broad_type, offset_category_general) %>%
  count(project_broad_type, offset_category_general, name = "n_studies")

# Step 4: Plot
ggplot(ecoact_plot_data,
       aes(x = fct_reorder(project_broad_type, n_studies, .fun = sum),
           y = n_studies,
           fill = offset_category_general)) +
  geom_col(position = position_dodge(width = 0.9), color = "black") +
  geom_text(aes(label = n_studies),
            position = position_dodge(width = 0.9),
            hjust = -0.4, size = 4, color = "black") +
  scale_fill_brewer(palette = "Pastel1") +
  labs(
    title = "# Studies by Ecological Action Type and Offset Category",
    x = "Ecological Action Type",
    y = "Number of Studies",
    fill = "Offset Category"
  ) +
  coord_flip() +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top",
    plot.margin = margin(1, 1.5, 1, 1, unit = "lines")
  )
```

The most common ecological actions discussed were **`r top1_type`** (`r top1_total` studies), followed by **`r top2_type`** (`r top2_total`), and **`r top3_type`** (`r top3_total`).  
**`r top_carbon_type`** was the action most frequently studied in carbon offset studies (`r top_carbon_n` studies), while **`r top_biodiversity_type`** was most common for biodiversity offset studies (`r top_biodiversity_n` studies).

------------------------------------------------------------------------

### 3.5. Program Type x Offset Category

Here I explore what programs were most common for each offset type. Due to the diversity of studies, these aren't technically all "programs" in the formal sense, but rather the governing mechanism delivering the offset.
```{r}
#| label: program-offset-category
#| echo: false

# Filter and summarize programs × offset category
program_offset_summary <- final_df %>%
  filter(
    !is.na(study_id),
    !is.na(program_name),
    !is.na(offset_category_general)
  ) %>%
  distinct(study_id, program_name, offset_category_general) %>%
  count(program_name, offset_category_general, name = "n_studies") %>%
  pivot_wider(names_from = offset_category_general, values_from = n_studies, values_fill = 0)

# Top 5 biodiversity and top 5 carbon programs
top5_bio <- program_offset_summary %>%
  arrange(desc(biodiversity)) %>%
  slice_head(n = 5)

top5_carbon <- program_offset_summary %>%
  arrange(desc(carbon)) %>%
  slice_head(n = 5)

# Combine and get top 10 unique programs
top10_programs <- bind_rows(top5_bio, top5_carbon) %>%
  distinct(program_name, .keep_all = TRUE)

# Add program_type (if available)
top10_programs_annotated <- top10_programs %>%
  left_join(
    final_df %>%
      select(program_name, program_type) %>%
      distinct(),
    by = "program_name"
  )

# Create variables for prose
top_bio_program <- top5_bio$program_name[1]
top_bio_n <- top5_bio$biodiversity[1]

top_carbon_program <- top5_carbon$program_name[1]
top_carbon_n <- top5_carbon$carbon[1]

# Display GT table (without Total)
top10_programs_annotated %>%
  gt() %>%
  tab_header(title = md("**Top Programs by Offset Category**")) %>%
  cols_label(
    program_name = "Program",
    program_type = "Program Type",
    biodiversity = "Biodiversity",
    carbon = "Carbon"
  ) %>%
  fmt_number(columns = c(biodiversity, carbon), decimals = 0) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(everything())
  )
```

```{r}
#| label: program-offset-barplot-single
#| echo: false
#| fig-width: 8
#| fig-height: 5

# Calculate total studies per program across both categories first
top_programs_total <- final_df %>%
  filter(!is.na(study_id), !is.na(program_name), !is.na(offset_category_general)) %>%
  distinct(study_id, program_name) %>%
  count(program_name, name = "total_n") %>%
  arrange(desc(total_n)) %>%
  slice_max(total_n, n = 10)

# Now get breakdown by offset category for those top 10 programs
top10_programs_clean <- final_df %>%
  filter(!is.na(study_id), !is.na(program_name), !is.na(offset_category_general)) %>%
  semi_join(top_programs_total, by = "program_name") %>%
  distinct(study_id, program_name, offset_category_general) %>%
  count(program_name, offset_category_general, name = "n_studies") %>%
  mutate(program_name = fct_reorder(program_name, n_studies, .fun = sum))

# ✅ NEW: Create annotated table with total studies per program
top10_programs_annotated <- top10_programs_clean %>%
  group_by(program_name) %>%
  mutate(Total = sum(n_studies)) %>%
  ungroup()

# Top program overall
top_program <- top10_programs_annotated %>%
  distinct(program_name, Total) %>%
  arrange(desc(Total)) %>%
  slice(1)

# Top per category
top_biodiversity <- top10_programs_annotated %>%
  filter(offset_category_general == "biodiversity") %>%
  arrange(desc(n_studies)) %>%
  slice(1)

top_carbon <- top10_programs_annotated %>%
  filter(offset_category_general == "carbon") %>%
  arrange(desc(n_studies)) %>%
  slice(1)

# Step 1: Total study counts per program
program_totals <- top10_programs_clean %>%
  group_by(program_name) %>%
  summarise(total_studies = sum(n_studies), .groups = "drop")

# Step 2: Plot
ggplot(top10_programs_clean,
       aes(x = program_name, y = n_studies, fill = offset_category_general)) +
  geom_col(position = "stack", color = "black") +
  geom_text(data = program_totals,
            aes(x = program_name, y = total_studies, label = total_studies),
            hjust = -0.2, size = 4, inherit.aes = FALSE) +
  scale_fill_brewer(palette = "Pastel1") +
  labs(
    title = "Top 10 Offset Programs by Number of Studies",
    x = "Program",
    y = "Number of Studies",
    fill = "Offset Category"
  ) +
  coord_flip(clip = "off") +  # Let labels go beyond plot area
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top",
    plot.margin = margin(1, 2, 1, 1, unit = "lines")  # Make room on right
  )

```

The most commonly identified offset program across biodiversity and carbon offset studies was **`r top_program$program_name`**, appearing in `r top_program$Total` studies.

Among biodiversity-focused programs, the most frequently mentioned was **`r top_biodiversity$program_name`**, with `r top_biodiversity$n_studies` studies.

For carbon offsets, **`r top_carbon$program_name`** was most common, with `r top_carbon$n_studies` studies.

------------------------------------------------------------------------

### 3.6. Policy Type x Offset Category
Where possible I also extracted the focal policies surrounding offset implementation (or for policy analyses, the policies that were being critiqued).
```{r}
#| label: policy-offset-category
#| echo: false

# Filter and summarize policies × offset category
policy_offset_summary <- final_df %>%
  filter(
    !is.na(study_id),
    !is.na(policy_name),
    !is.na(offset_category_general)
  ) %>%
  distinct(study_id, policy_name, offset_category_general) %>%
  count(policy_name, offset_category_general, name = "n_studies") %>%
  pivot_wider(names_from = offset_category_general, values_from = n_studies, values_fill = 0)

# Top 5 biodiversity and top 5 carbon policies
top5_bio_policy <- policy_offset_summary %>%
  arrange(desc(biodiversity)) %>%
  slice_head(n = 5)

top5_carbon_policy <- policy_offset_summary %>%
  arrange(desc(carbon)) %>%
  slice_head(n = 5)

# Combine and deduplicate to get top 10 unique policies
top10_policies <- bind_rows(top5_bio_policy, top5_carbon_policy) %>%
  distinct(policy_name, .keep_all = TRUE)

# Join policy_type if available
top10_policies_annotated <- top10_policies %>%
  left_join(
    final_df %>%
      select(policy_name, policy_type) %>%
      distinct(),
    by = "policy_name"
  )

# Display GT table (no Total column)
top10_policies_annotated %>%
  gt() %>%
  tab_header(title = md("**Top Policies by Offset Category**")) %>%
  cols_label(
    policy_name = "Policy",
    policy_type = "Policy Type",
    biodiversity = "Biodiversity",
    carbon = "Carbon"
  ) %>%
  fmt_number(columns = c(biodiversity, carbon), decimals = 0) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(everything())
  )
```

```{r}
#| label: policy-offset-barplot-single
#| echo: false
#| fig-width: 8
#| fig-height: 5

# Step 1: Get top 10 policies (5 per category)
policy_offset_data <- final_df %>%
  filter(!is.na(study_title), !is.na(policy_name), !is.na(offset_category_general)) %>%
  distinct(study_id, policy_name, offset_category_general) %>%
  count(policy_name, offset_category_general, name = "n_studies") %>%
  group_by(offset_category_general) %>%
  slice_max(n_studies, n = 5) %>%
  ungroup() %>%
  distinct(policy_name, .keep_all = TRUE) %>%
  rename(Total = n_studies)

# Step 2: Prepare for plotting
policy_plot_clean <- policy_offset_data %>%
  mutate(
    policy_name = fct_reorder(policy_name, Total),
    offset_category = offset_category_general
  )

# Step 3: Plot
ggplot(policy_plot_clean,
       aes(x = policy_name, y = Total, fill = offset_category)) +
  geom_col(color = "black") +
  geom_text(aes(label = Total),
            hjust = -0.3, size = 4, color = "black") +
  scale_fill_brewer(palette = "Pastel1") +
  labs(
    title = "Top 10 Offset Policies by Number of Studies",
    x = "Policy",
    y = "Number of Studies",
    fill = "Offset Category"
  ) +
  coord_flip() +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top"
  )
```

The US CWA Section 404 was the most common policy discussed, followed by UNFCCC REDD+ (which is not necessarily a single policy, per se, but treated as a single legal instrument for this classification).

------------------------------------------------------------------------

## 4. Permanence Risks
Lets now move onto the permanence risks. Here I explore the types, frequencies, geographic patterns, and co-occurrences of permanence risks discussed in the literature.

### 4.1. Summary of Permanence Risks
Below is a table of the permanence risks broken down by domain (non-physical, physical, methodological), category, and type, with the counts for how many studies evidenced such risks. Non-physical were the most common, followed by physical and then methodological risks.
```{r}
#| label: permanence-risk-summary
#| echo: false

# Step 1: Filter relevant rows
risk_data <- final_df %>%
  filter(
    !is.na(permanence_risk_domain),
    !is.na(permanence_risk_category),
    !is.na(permanence_risk_type)
  ) %>%
  distinct(study_id, permanence_risk_domain, permanence_risk_category, permanence_risk_type)

# Step 2: Count number of unique studies at each level
type_counts <- risk_data %>%
  count(permanence_risk_domain, permanence_risk_category, permanence_risk_type, name = "n_studies_type")

category_counts <- risk_data %>%
  distinct(study_id, permanence_risk_domain, permanence_risk_category) %>%
  count(permanence_risk_domain, permanence_risk_category, name = "n_studies_category")

domain_counts <- risk_data %>%
  distinct(study_id, permanence_risk_domain) %>%
  count(permanence_risk_domain, name = "n_studies_domain")

# Step 3: Join all into nested table
nested_summary <- type_counts %>%
  left_join(category_counts, by = c("permanence_risk_domain", "permanence_risk_category")) %>%
  left_join(domain_counts, by = "permanence_risk_domain") %>%
  arrange(
    desc(n_studies_domain),
    desc(n_studies_category),
    desc(n_studies_type)
  ) %>%
  rename(
    `Risk Domain` = permanence_risk_domain,
    `# Studies (Domain)` = n_studies_domain,
    `Risk Category` = permanence_risk_category,
    `# Studies (Category)` = n_studies_category,
    `Risk Type` = permanence_risk_type,
    `# Studies (Type)` = n_studies_type
  )

# Step 4a: Display nested table
nested_summary %>%
  select(
    `Risk Domain`, `# Studies (Domain)`,
    `Risk Category`, `# Studies (Category)`,
    `Risk Type`, `# Studies (Type)`
  ) %>%
  gt() %>%
  tab_header(title = md("**Permanence Risks: Study Counts by Domain, Category, and Type**")) %>%
  cols_align(align = "left", columns = everything()) %>%
  tab_options(table.font.size = "small", data_row.padding = px(2)) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(everything())
  )

# Step 4b: Save for export
write.csv(nested_summary,
          file = here::here("output", "figures", "permanence_risk_nested_summary.csv"),
          row.names = FALSE)

```

#### 4.1.1. Table: Permanence Risk Types
Here I provide basically the same table, but with the specific permanence risk types organized in decreasing order. Of the top 5 most common risks, 4 were non-physical and 1 methodological.
```{r}
#| label: permanence-risk-type-flat
#| echo: false

# Count and sort just the types using unique study_id
final_risk_type_table <- final_df %>%
  filter(!is.na(permanence_risk_type)) %>%
  distinct(study_id, permanence_risk_domain, permanence_risk_category, permanence_risk_type) %>%
  count(permanence_risk_domain, permanence_risk_category, permanence_risk_type, name = "n_studies") %>%
  arrange(desc(n_studies)) %>%
  gt() %>%
  tab_header(title = md("**Permanence Risk Types (with Domain and Category)**")) %>%
  cols_label(
    permanence_risk_domain = "Domain",
    permanence_risk_category = "Category",
    permanence_risk_type = "Risk Type",
    n_studies = "Study Count"
  ) %>%
  cols_align(align = "left", columns = everything()) %>%
  tab_options(table.font.size = "small", data_row.padding = px(2)) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(everything())
  )

final_risk_type_table

```



#### 4.1.2. Unique Risks per Study
The plot below shows how many different types of permanence risks are mentioned in each study. Each bar represents the number of studies that cite a certain number of unique risk types. For example, 48 studies cited only one distinct risk type, whereas 64 studies cited two different risk types. Essentially, many studies discussed one or two risks, with several discussing between 3-5 risks.
```{r}
#| label: unique-risks-per-study
#| echo: false

# Count unique risks per study
risk_counts <- final_df %>%
  filter(!is.na(permanence_risk_type)) %>%
  group_by(study_id, program_name, continent) %>%
  summarise(n_unique_risks = n_distinct(permanence_risk_type), .groups = "drop")

# Plot
ggplot(risk_counts, aes(x = n_unique_risks)) +
  geom_bar(fill = "steelblue") +
  geom_text(stat = "count", aes(label = after_stat(count)), vjust = -0.4) +
  labs(
  title = "How Many Different Permanence Risks Are Cited per Study?",
  x = "# of Distinct Risk Types Cited",
  y = "# of Studies"
) +
  theme_minimal()
```

#### 4.1.3. Risks by Offset Type
Here I break down the risks (risk domain, category, and type) by offset type (biodiversity or carbon) to get a better sense of what patterns exist between the two bodies of literature.

##### Risk Domain x Offset Type

```{r}
#| label: bar-risk-domain-offset-horizontal
#| echo: false
#| fig-width: 9
#| fig-height: 5

# Summarize risk domain × offset category using study_id
risk_domain_summary <- final_df %>%
  filter(!is.na(permanence_risk_domain), !is.na(offset_category_general)) %>%
  distinct(study_id, permanence_risk_domain, offset_category_general) %>%
  count(permanence_risk_domain, offset_category_general, name = "n_studies")

# Plot horizontal bar chart
ggplot(risk_domain_summary,
       aes(x = fct_reorder(permanence_risk_domain, n_studies, .fun = sum),
           y = n_studies,
           fill = offset_category_general)) +
  geom_col(position = position_dodge(width = 0.9), color = "black") +
  geom_text(aes(label = n_studies),
            position = position_dodge(width = 0.9),
            hjust = -0.5, size = 3.7, color = "black") +
  scale_fill_brewer(palette = "Pastel1") +
  labs(
    title = "Studies by Risk Domain and Offset Category",
    x = "Risk Domain",
    y = "Number of Studies",
    fill = "Offset Category"
  ) +
  coord_flip() +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top"
  )

```
Biodiversity offset studies most frequently discussed non-physical and methodological risks, and physical risks were least discussed. Carbon offset studies similarly discussed non-physical risks the most, followed by physical and then methodological.


##### Risk Category x Offset Type
Here I go a level deeper to Risk Category. This figure shows how often each permanence risk category is discussed across biodiversity and carbon offset studies. Each bar represents the number of studies that mention a given risk category, grouped by offset type. Studies can appear in multiple categories (because many studies discussed multiple risks), so totals may exceed the number of unique studies.
```{r}
#| label: bar-risk-category-offset-horizontal
#| echo: false
#| fig-width: 9
#| fig-height: 6

# Step 0: Manual risk category order by domain
risk_cat_order <- c(
  # Non-physical
  "Compliance, Legal, and Governance Risks",
  "Data, Transparency, and Capacity Issues",
  "Financial Risks",
  "Political Risks",
  "Socioeconomic and Equity Risks",
  # Physical
  "Climate and Environmental Disturbances",
  "Direct Anthropogenic Disturbances",
  # Methodological
  "Ecological Design and Implementation Failures",
  "Misaligned Metrics, Standards, and Performance Criteria",
  "Systemic Oversights and Risk Management Gaps"
)

# Step 1: Map categories to domains
risk_cat_domain_map <- tibble::tibble(
  permanence_risk_category = risk_cat_order,
  domain = c(
    rep("non-physical", 5),
    rep("physical", 2),
    rep("methodological", 3)
  )
)

# Step 2: Prepare data
risk_category_summary <- final_df %>%
  filter(!is.na(permanence_risk_category), !is.na(offset_category_general)) %>%
  distinct(study_id, permanence_risk_category, offset_category_general) %>%
  count(permanence_risk_category, offset_category_general, name = "n_studies") %>%
  filter(permanence_risk_category %in% risk_cat_order) %>%
  left_join(risk_cat_domain_map, by = "permanence_risk_category") %>%
  mutate(permanence_risk_category = factor(permanence_risk_category, levels = rev(risk_cat_order)))

# Step 3: Get numeric position for each category
category_positions <- risk_cat_domain_map %>%
  mutate(pos = rev(seq_along(permanence_risk_category)))

# Step 4: Compute domain break positions
domain_breaks <- category_positions %>%
  group_by(domain) %>%
  summarise(max_pos = max(pos), .groups = "drop") %>%
  arrange(match(domain, c("non-physical", "physical", "methodological"))) %>%
  mutate(line_y = max_pos + 0.5)   # don't add a line after the last group

# Step 5: Plot
ggplot(risk_category_summary,
       aes(x = permanence_risk_category, y = n_studies, fill = offset_category_general)) +
  geom_col(position = position_dodge(width = 0.9), color = "black", width = 0.75) +
  geom_text(aes(label = n_studies),
            position = position_dodge(width = 0.9),
            hjust = -0.3,
            size = 3.5,
            color = "black") +
  geom_segment(
    data = domain_breaks,
    aes(y = 0, yend = Inf, x = line_y, xend = line_y),
    inherit.aes = FALSE,
    linetype = "dashed",
    color = "black"
  ) +
  scale_fill_brewer(palette = "Pastel1") +
  labs(
    title = "Studies by Risk Category and Offset Category",
    x = "Risk Category",
    y = "Number of Studies",
    fill = "Offset Category"
  ) +
  coord_flip(clip = "off") +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "top",
    plot.margin = margin(1, 2, 1, 1, unit = "lines")
  )

```

##### Heatmap: Risk Category x Offset Type
```{r}
#| label: risk-category-heatmap-offset
#| echo: false
#| fig-width: 8
#| fig-height: 6

# Step 1: Count unique studies mentioning each risk category per offset type
heatmap_data <- final_df %>%
  filter(!is.na(permanence_risk_category), !is.na(offset_category_general)) %>%
  distinct(study_id, permanence_risk_category, offset_category_general) %>%
  count(offset_category_general, permanence_risk_category, name = "n_studies")

# Step 2: Get total study count per offset type
total_per_offset <- final_df %>%
  filter(!is.na(offset_category_general)) %>%
  distinct(study_id, offset_category_general) %>%
  count(offset_category_general, name = "total_studies")

# Step 3: Join and calculate percentage
heatmap_df <- heatmap_data %>%
  left_join(total_per_offset, by = "offset_category_general") %>%
  mutate(
    prop = n_studies / total_studies,
    label = percent(prop, accuracy = 1),
    text_color = ifelse(prop <= 0.05, "white", "black"),
    permanence_risk_category = fct_reorder(permanence_risk_category, prop, .fun = max)
  )

heatmap_df <- heatmap_df %>%
  mutate(
    text_color = if_else(prop < 0.3, "white", "black")
  )

# Step 4: Plot heatmap
ggplot(heatmap_df, aes(x = offset_category_general, y = permanence_risk_category, fill = prop)) +
  geom_tile(color = "white") +
 geom_text(
  aes(label = scales::percent(prop, accuracy = 1), color = text_color),
  size = 3
) +
scale_color_identity()+
  scale_fill_stepsn(
  colours = viridis::viridis(10, option = "plasma"),
  breaks = seq(0, 1, by = 0.10),
  labels = scales::percent_format(accuracy = 1),
  name = "Percentage"
) +
  scale_color_identity() +
  labs(
    title = "Proportion of Studies Mentioning Each Risk Category",
    x = "Offset Category",
    y = "Permanence Risk Category",
    fill = "Percentage"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid = element_blank()
  )

```
A majority (57%) of biodiversity offset studies identified compliance, legal, and governance risks, whereas 51% of carbon offset studies identified socioeconomic and equity risks.

##### Risk Type x Offset Type Split Plot
Now I go another level deeper to Risk Type (the most fine-scale risk categorization). I have created a split bar plot rather than the dual bar plots like above. Risks are grouped into domains (separated by dark dotted lines) and risk categories (light grey dotted lines). Each horizontal bar represents a risk type, with pink bars showing mentions in biodiversity studies and blue bars showing mentions in carbon studies. The longer the bar, the more frequently that risk type appears in the literature.
```{r}
#| label: diverging-bar-risk-domain-category-type
#| echo: false
#| fig-width: 12
#| fig-height: 10

# Define manual domain order
domain_order <- c("non-physical", "physical", "methodological")

# Apply ordering and arrange data
risk_clean <- final_df %>%
  filter(
    !is.na(permanence_risk_domain),
    !is.na(permanence_risk_category),
    !is.na(permanence_risk_type),
    !is.na(offset_category_general)
  ) %>%
  distinct(study_id, permanence_risk_domain, permanence_risk_category, permanence_risk_type,
           offset_category_general) %>%
  count(permanence_risk_domain, permanence_risk_category, permanence_risk_type, offset_category_general, name = "n") %>%
  pivot_wider(names_from = offset_category_general, values_from = n, values_fill = 0) %>%
  mutate(
    total = biodiversity + carbon,
    permanence_risk_domain = factor(permanence_risk_domain, levels = domain_order)
  ) %>%
  arrange(permanence_risk_domain, permanence_risk_category, desc(total)) %>%
  mutate(risk_type_label = factor(permanence_risk_type, levels = rev(unique(permanence_risk_type))))

# Order for plotting
risk_clean <- risk_clean %>%
  arrange(permanence_risk_domain, permanence_risk_category, desc(total)) %>%
  mutate(risk_type_label = paste0(permanence_risk_type)) %>%
  mutate(risk_type_label = factor(risk_type_label, levels = rev(unique(risk_type_label))))

# Long format for diverging bars
risk_long <- risk_clean %>%
  select(permanence_risk_domain, permanence_risk_category, risk_type_label, biodiversity, carbon) %>%
  pivot_longer(cols = c(biodiversity, carbon), names_to = "offset_category", values_to = "n") %>%
  mutate(n = if_else(offset_category == "biodiversity", -n, n))

# Line positions: category-level
risk_positions <- risk_clean %>%
  mutate(row = as.numeric(factor(risk_type_label, levels = levels(risk_type_label)))) %>%
  group_by(permanence_risk_domain, permanence_risk_category) %>%
  summarise(max_row = max(row), .groups = "drop") %>%
  arrange(permanence_risk_domain, permanence_risk_category) %>%
  mutate(line_y = max_row + 0.5)

# Line positions: domain-level
domain_breaks <- risk_clean %>%
  mutate(row = as.numeric(factor(risk_type_label, levels = levels(risk_type_label)))) %>%
  group_by(permanence_risk_domain) %>%
  summarise(max_row = max(row), .groups = "drop") %>%
  arrange(permanence_risk_domain) %>%
  mutate(line_y = max_row + 0.5)

# Create label dataframe with proper coordinates
risk_labels <- risk_long %>%
  filter(n != 0) %>%
  mutate(
    hjust_val = if_else(n < 0, 1.3, -0.3),
    y_val = n,  # y value for plotting
    x_val = risk_type_label  # x value (factor)
  )

# Plot
ggplot(risk_long, aes(x = risk_type_label, y = n, fill = offset_category)) +
  geom_col(color = "black") +
  geom_text(
    data = risk_labels,
    aes(x = x_val, y = y_val, label = abs(n), hjust = hjust_val),
    size = 4,
    color = "black",
    inherit.aes = FALSE
  ) +
  geom_hline(yintercept = 0, color = "gray40") +
  geom_segment(
    data = risk_positions,
    aes(x = line_y, xend = line_y, y = -Inf, yend = Inf),
    inherit.aes = FALSE,
    linetype = "dashed",
    color = "gray70"
  ) +
  geom_segment(
    data = domain_breaks,
    aes(x = line_y, xend = line_y, y = -Inf, yend = Inf),
    inherit.aes = FALSE,
    linetype = "dashed",
    color = "black",
    linewidth = 1
  ) +
  scale_fill_brewer(palette = "Pastel1", name = "Offset Category") +
  scale_y_continuous(labels = function(x) abs(x)) +
  coord_flip() +
  labs(
    title = "Risk Type by Offset Category",
    x = "Risk Type",
    y = "Number of Studies"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.y = element_text(size = 10),
    legend.position = "top"
  )
```
**Key Patterns**
Non-physical risks dominate in biodiversity offset studies. The top three were Policy non-compliance (27 biodiversity vs 2 carbon), Limited data transparency (28 vs 2), and Poor management and monitoring (23 vs 4). There seems to be a clear focus more on the legal, governance, data, and capacity issues within the biodiversity offset literature.

For carbon offsets, Socioeconomic and Equity Risks (Land tenure, inadequate compensation, opportunity costs) were more prevalent. This was likely due to the high number of REDD/REDD+ studies that focus on low- and middle-income countries, where legal and governance safeguards may not be as developed or enforced as in higher income countries. 

Physical risks were generally more evenly cited between the two offset categories. Fire was the most common physical risk and was almost exclusively limited to carbon offset studies, likely due to the emphasis on forest carbon offsets. Flooding was only associated with biodiversity offset studies, likely due to the high number focusing on wetland biodiversity offsets.

Within the methodological risks section, biodiversity offset studies tended to identify more site/project level risks, as well as issues associated with metric choice and standards. This could be attributed to several things: biodiversity is more difficult to measure than carbon (so many metric/standards issues); many of the studies focused on wetland offsets, which are technically more challenging to deliver than terrestrial offsets due to added complexities from hydrology. Management or program-level risks (ie portfolio-level risks) were more common for carbon offset studies, which seem to have more developed mechanisms for managing multiple offset projects.

##### Risk Type x Offset Type Heatmap
Here I visualize the same plot as a heatmap.
```{r}
#| label: heatmap-risk-type-offset
#| echo: false
#| fig-width: 7
#| fig-height: 7

# Get the consistent risk type ordering from earlier diverging bar
risk_type_levels <- levels(risk_clean$risk_type_label)

# Prepare the data
risk_type_heat <- final_df %>%
  filter(!is.na(permanence_risk_type), !is.na(offset_category_general)) %>%
  distinct(study_title, permanence_risk_type, offset_category_general) %>%
  count(permanence_risk_type, offset_category_general, name = "n") %>%
  complete(permanence_risk_type, offset_category_general, fill = list(n = 0)) %>%
  mutate(risk_type_label = factor(permanence_risk_type, levels = risk_type_levels))

# Number fill colors
risk_type_heat <- risk_type_heat %>%
  mutate(text_color = case_when(
    n == 0 ~ "black",        # Always black for zeros
    n <= 4 ~ "white",        # Light fill = dark text
    TRUE ~ "black"           # Dark fill = white text
  ))

# Plot the heatmap
ggplot(risk_type_heat, aes(x = offset_category_general, y = risk_type_label)) +
  
  # Gray tile for zeros
  geom_tile(data = subset(risk_type_heat, n == 0),
            fill = "gray90", color = "white", width = 1) +
  
  # Colored tile for values > 0
  geom_tile(data = subset(risk_type_heat, n > 0),
            aes(fill = n), color = "white", width = 1) +
  
  # Text labels
  geom_text(aes(label = n, color = text_color), size = 3, show.legend = FALSE) +
scale_color_identity() +

  # Fill scale for >0 counts
  scale_fill_viridis_c(option = "viridis", trans = "log1p") +
  
  # Labels and theme
  labs(
    title = "Risk Type by Offset Category",
    x = "Offset Category",
    y = "Risk Type",
    fill = "Study Count"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    axis.text.y = element_text(size = 8, lineheight = 1.1),
    plot.title = element_text(hjust = 0.5)
  )

```

### 4.2. Permanence Risk Co-occurence
This section explores which permanence risks are most frequently cited together. I look at co-occurring **risk pairs and triplets**, and the tables below show how often two risks or three risks appeared across the studies reviewed.

```{r}
#| label: permanence-risk-cooccurrence
#| echo: false

# Helper function to generate combinations of elements
get_combos <- function(items, combo_size = 2) {
  if (length(items) < combo_size) return(NULL)
  combn(items, combo_size, simplify = FALSE)
}

# Generate all risk combinations per study
risk_sets <- final_df %>%
  filter(!is.na(permanence_risk_type)) %>%
  group_by(study_title) %>%
  summarise(risks = list(unique(permanence_risk_type)), .groups = "drop")

# Count co-occurring risk pairs
pair_counts <- risk_sets %>%
  mutate(pairs = map(risks, get_combos, combo_size = 2)) %>%
  unnest(pairs) %>%
  mutate(pair = map_chr(pairs, ~ str_c(sort(.x), collapse = " + "))) %>%
  count(pair, sort = TRUE)

# Count co-occurring risk triplets
triplet_counts <- risk_sets %>%
  mutate(triplets = map(risks, get_combos, combo_size = 3)) %>%
  unnest(triplets) %>%
  mutate(triplet = map_chr(triplets, ~ str_c(sort(.x), collapse = " + "))) %>%
  count(triplet, sort = TRUE)
```

The top 8 most frequently co-occurring risks were non-physical.

```{r}
#| label: top-10-pairs-triplets
#| echo: false
# Display top 10 pairs
pair_counts %>%
  slice_max(n, n = 10) %>%
  gt() %>%
  tab_header(title = md("**Top 10 Co-occurring Risk Pairs**")) %>%
  cols_label(pair = "Risk Pair", n = "Number of Studies") %>%
  fmt_number(columns = n, decimals = 0) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(everything())
  )

# Display top 10 triplets
triplet_counts %>%
  slice_max(n, n = 10) %>%
  gt() %>%
  tab_header(title = md("**Top 10 Co-occurring Risk Triplets**")) %>%
  cols_label(triplet = "Risk Triplet", n = "Number of Studies") %>%
  fmt_number(columns = n, decimals = 0) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(everything())
  )
```


#### 4.2.1. Heatmap: Frequency of Risk Pairs x Offset Category
Here I break down the frequency of how often the top 10 risk pairs appear in biodiversity offset studies vs carbon offset studies.
```{r}
#| label: risk-pair-frequency-heatmap
#| echo: false
#| fig-width: 8
#| fig-height: 6

# Prepare data for heatmap
pair_by_offset <- final_df %>%
  filter(!is.na(permanence_risk_type), !is.na(offset_category_general)) %>%
  group_by(study_title, offset_category_general) %>%
  summarise(risks = list(unique(permanence_risk_type)), .groups = "drop") %>%
  mutate(pairs = map(risks, get_combos, combo_size = 2)) %>%
  unnest(pairs) %>%
  mutate(risk_pair = map_chr(pairs, ~ str_c(sort(.x), collapse = " + "))) %>%
  count(offset_category_general, risk_pair)

# Top 10 pairs only
top_pairs <- pair_counts %>%
  slice_max(n, n = 10) %>%
  rename(risk_pair = pair) %>%
  mutate(risk_pair = str_to_lower(str_trim(risk_pair)))

# Filter heatmap data to top 10 pairs
pair_heat <- pair_by_offset %>%
  mutate(risk_pair = str_to_lower(str_trim(risk_pair))) %>%
  filter(risk_pair %in% top_pairs$risk_pair) %>%
  complete(offset_category_general, risk_pair, fill = list(n = 0))

# Plot
ggplot(pair_heat, aes(x = offset_category_general, y = fct_reorder(risk_pair, n), fill = n)) +
  geom_tile(color = "white", linewidth = 0.5, width = 1) +
  geom_text(aes(label = n), color = "black", size = 3) +
  scale_fill_viridis_c(
    option = "mako",
    trans = "log1p",
    begin = 0.1,
    end = 0.9
  ) +
  labs(
    title = "Top Risk Pairs by Offset Category",
    x = "Offset Category",
    y = "Risk Type Pair",
    fill = "Study Count"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_text(lineheight = 1.1),
    plot.title = element_text(hjust = 1),
    legend.position = "right"
  )
```
**Key Patterns**

For biodiversity offset studies, compliance, legal, and governance risks were commonly associated with data, transparency, and capacity issues. 

For carbon offset studies, individual climate and environmental disturbances (ie fire and drought) often co-occurred. In addition, socioeconomic and equity risks were often common with compliance, legal, and governance risks.

------------------------------------------------------------------------------

### 4.3. Geographic Trends in Permanence Risks
Here I explore some of the geographic trends in permanence risks. 

#### 4.3.1. Top Three Risks in Top Ten Most Frequent Countries
The table below summarizes the top three permanence risk types identified in the ten most represented countries in the dataset (i.e., the countries with the highest number of studies mentioning any permanence risk). 

For each country, the three most frequently cited risk types are shown, along with:

1. The number of studies from that country that identified the given risk type.

2. The total number of studies across all countries that identified that same risk type.

3. The proportion of global mentions of that risk type that came from the given country.

For example, a high proportion (~50%) indicates that a large share of the literature in the dataset that mentions that risk is concentrated in that country. This could suggest either stronger relevance, reporting bias, or more frequent occurrence in that national context.

```{r}
#| label: top-3-risks-top10-countries
#| echo: false

# Step 1: Global total per risk type
global_risk_totals <- final_df %>%
  filter(!is.na(permanence_risk_type)) %>%
  distinct(study_id, permanence_risk_type) %>%
  count(permanence_risk_type, name = "global_total")

# Step 2: Study count per country and risk type
risk_by_country <- final_df %>%
  filter(!is.na(country), !is.na(permanence_risk_type)) %>%
  distinct(study_id, country, permanence_risk_type) %>%
  count(country, permanence_risk_type, name = "n_studies")

# Step 3: Top 10 countries by risk-related study count
top10_countries <- final_df %>%
  filter(!is.na(country), !is.na(permanence_risk_type)) %>%
  distinct(study_id, country) %>%
  count(country, name = "country_total") %>%
  slice_max(country_total, n = 10)

# Step 4: Build table
risk_table_grouped <- risk_by_country %>%
  semi_join(top10_countries, by = "country") %>%
  left_join(global_risk_totals, by = "permanence_risk_type") %>%
  left_join(top10_countries, by = "country") %>%
  mutate(share = n_studies / global_total) %>%
  group_by(country) %>%
  slice_max(n_studies, n = 3, with_ties = FALSE) %>%  # Top 3 risks per country
  ungroup() %>%
  mutate(country = factor(country, levels = top10_countries$country)) %>%  # enforce country order
  arrange(country, desc(n_studies))  # <- Sort by study count within each country

# drop country total column
risk_table_grouped <- risk_table_grouped %>%
  select(-country_total)  # Drop column to avoid confusion

# Step 5: Display table
risk_table_grouped %>%
  gt() %>%
  tab_header(
    title = "Top 3 Permanence Risks in the 10 Most Represented Countries"
  ) %>%
  cols_label(
    country = "Country",
    permanence_risk_type = "Permanence Risk Type",
    n_studies = "Studies in Country",
    global_total = "Global Studies",
    share = "Share of Global"
  ) %>%
  fmt_percent(columns = share, decimals = 1) %>%
  fmt_number(columns = c(n_studies, global_total), decimals = 0) %>%
    tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(everything()))
```

The United States was over-represented in the dataset, which is unsurprising given the substantial body of literature on the US wetland mitigation system. Nearly half of the top three risks came from studies looking at the United States.

Of the top 10 most represented countries in the dataset, limited data transparency was a pervasive risk across developed countries like the U.S, Australia, Canada, U.K., France, and New Zealand. On the other hand, less developed countries (Brazil, Indonesia, Nigeria, Tanzania) exhibited more Socioeconomic and Equity Risks (Land Tenure and Access Conflicts, Incentive Misalignment, Opportunity Costs, and Landowner Behaviour, Community Exclusion and Compensation Gaps).

#### 4.3.2. Heatmap: Risk Category Frequency by Continent
Here I break down the frequency in which the risk categories appeared across the continents represented. Rather than a bar plot, I present this as a heatmap.
```{r}
#| label: risk-heatmap-by-continent
#| echo: false

library(dplyr)
library(ggplot2)
library(tidyr)
library(forcats)
library(scales)

# Step 1: Get all combinations of continent and risk category
all_combos <- expand.grid(
  continent = unique(na.omit(final_df$continent)),
  permanence_risk_category = unique(na.omit(final_df$permanence_risk_category)),
  stringsAsFactors = FALSE
)

# Step 2: Count unique studies by continent × risk category
heatmap_data <- final_df %>%
  filter(!is.na(permanence_risk_category), !is.na(continent)) %>%
  distinct(study_id, continent, permanence_risk_category) %>%
  count(continent, permanence_risk_category, name = "n_studies")

# Step 3: Complete missing combinations and reorder
heatmap_complete <- all_combos %>%
  left_join(heatmap_data, by = c("continent", "permanence_risk_category")) %>%
  mutate(
    n_studies = replace_na(n_studies, 0),
    permanence_risk_category = fct_reorder(permanence_risk_category, n_studies, .fun = sum),
    
    # Step 4: Add dynamic text color for readability
    text_color = case_when(
      n_studies == 0 ~ "white",       # Always black for zeroes
      n_studies <= 1 ~ "white",       # Low fill = dark background
      TRUE ~ "black"                  # High fill = light background
    )
  )

# refactor
heatmap_complete <- heatmap_complete %>%
  mutate(
    continent = factor(continent, levels = c(
      "North America", "South America", "Europe", "Asia", "Oceania", "Africa"
    ))
  )

# Step 5: Plot heatmap with readable text
ggplot(heatmap_complete, aes(x = continent, y = permanence_risk_category, fill = n_studies)) +
  geom_tile(color = "white") +
  geom_text(aes(label = n_studies, color = text_color), size = 3) +
  scale_fill_viridis_c(
    option = "magma",
    trans = "log1p",
    limits = c(0, max(heatmap_complete$n_studies)),
    begin = 0.2, end = 0.9
  ) +
  scale_color_identity() +  # Use colors from text_color column directly
  labs(
    title = "Frequency of Permanence Risk Categories by Continent",
    x = "Continent",
    y = "Permanence Risk Category",
    fill = "Number of Studies"
  ) +
  theme_minimal(base_size = 11) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank(),
    plot.title = element_text(hjust = 1)
  )
```
Here I normalize by the total number of studies per continent, to better account for regions that have more or less data (to control of sample size imbalance across continents and to to make it comparable between regions). This allows me to compare risk prominence between regions.
```{r}
#| label: risk-heatmap-by-continent-normalized
#| echo: false

# Step 1: Get all combinations of continent and risk category
all_combos <- expand.grid(
  continent = unique(na.omit(final_df$continent)),
  permanence_risk_category = unique(na.omit(final_df$permanence_risk_category)),
  stringsAsFactors = FALSE
)

# Step 2: Count studies by continent × risk category
heatmap_data <- final_df %>%
  filter(!is.na(permanence_risk_category), !is.na(continent)) %>%
  distinct(study_id, continent, permanence_risk_category) %>%
  count(continent, permanence_risk_category, name = "n_studies")

# Step 3: Get total studies per continent
total_per_continent <- final_df %>%
  filter(!is.na(study_id), !is.na(continent)) %>%
  distinct(study_id, continent, permanence_risk_category) %>%
  count(continent, name = "total_studies")

# Step 4: Join and normalize
heatmap_normalized <- all_combos %>%
  left_join(heatmap_data, by = c("continent", "permanence_risk_category")) %>%
  left_join(total_per_continent, by = "continent") %>%
  mutate(
    n_studies = replace_na(n_studies, 0),
    total_studies = replace_na(total_studies, 1),  # Avoid divide-by-zero
    prop = n_studies / total_studies,
    text_color = ifelse(prop <= 0.03, "white", "black"),
    permanence_risk_category = fct_reorder(permanence_risk_category, prop, .fun = sum)
  )

# Optional: Refactor continent order
heatmap_normalized <- heatmap_normalized %>%
  mutate(
    continent = factor(continent, levels = c(
      "North America", "South America", "Europe", "Asia", "Oceania", "Africa"
    ))
  )

# Step 5: Plot normalized heatmap
ggplot(heatmap_normalized, aes(x = continent, y = permanence_risk_category, fill = prop)) +
  geom_tile(color = "white") +
  geom_text(aes(label = scales::percent(prop, accuracy = 1), color = text_color), size = 3) +
  scale_fill_viridis_c(
    option = "viridis",
    limits = c(0, 0.5),
    begin = 0.2, end = 0.9,
    labels = percent_format(accuracy = 1)
  ) +
  scale_color_identity() +
  labs(
    title = "Proportion of Studies by Risk Category and Continent",
    x = "Continent",
    y = "Permanence Risk Category",
    fill = "Proportion"
  ) +
  theme_minimal(base_size = 11) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank(),
    plot.title = element_text(hjust = 0.5)
  )
```
**Key Patterns**

Compliance, Legal, and Governance Risks were identified consistently across all continents. Generally, North America had a relatively balanced risk profile (many risks identified, likely due to high number of studies). Nearly 50% of the studies focused on Europe identified Data, Transparency, and Capacity Issues as permanence risks. Outside of North America and Oceania, methodological risks were rare. Socioeconomic and Equity Risks were especially prominent in Africa, South America, and Asia, while largely absent in Europe, North America, and Oceania.

#### 4.3.3. Table: Risk Category x Continent

This table shows how many unique studies mentioned each permanence risk category across different continents. Each row corresponds to a risk category, while the columns indicate the number of studies that identified that category within a given continent. The "Global" column shows the total number of studies (across all continents) that referenced each category.

Here, a study is only counted once per risk category per continent, even if it mentioned the same category multiple times. As a result, global totals may differ slightly from overall totals as studies could have multiple region assignments.

```{r}
#| label: table-risk-category-by-continent
#| echo: false

# Step 1: Count unique studies per category × continent
category_by_continent <- final_df %>%
  filter(!is.na(permanence_risk_category), !is.na(continent)) %>%
  distinct(study_id, permanence_risk_category, continent) %>%
  count(permanence_risk_category, continent, name = "n") %>%
  pivot_wider(names_from = continent, values_from = n, values_fill = 0)

# Step 2: Add global total and sort
category_table <- category_by_continent %>%
  mutate(Global = rowSums(across(where(is.numeric)))) %>%
  arrange(desc(Global))

# Step 3: Identify which continent has the max per row
continent_columns <- setdiff(names(category_table), c("permanence_risk_category", "Global"))

# Store max continent for styling, but keep original table clean
max_continent_vector <- category_table %>%
  rowwise() %>%
  mutate(max_continent = continent_columns[which.max(c_across(all_of(continent_columns)))]) %>%
  pull(max_continent)

# Step 4: Create GT table (without the max_continent column)
gt_tbl <- category_table %>%
  gt() %>%
  tab_header(title = "Permanence Risk Category Mentions by Continent") %>%
  fmt_number(columns = where(is.numeric), decimals = 0) %>%
  cols_label(permanence_risk_category = "Risk Category") %>%
  tab_style(
  style = cell_text(weight = "bold"),
  locations = cells_column_labels(everything())
  )

# Step 5: Bold the maximum value per row (using pre-computed vector)
for (i in seq_along(continent_columns)) {
  col <- continent_columns[i]
  gt_tbl <- gt_tbl %>%
    tab_style(
      style = cell_text(weight = "bold"),
      locations = cells_body(
        columns = all_of(col),
        rows = which(max_continent_vector == col)
      )
    )
}

# Step 6: Show the final table
gt_tbl

```

Unsurprisingly, North America dominates in terms of overall risk frequency. Compliance, Legal, and Governance Risks tend to appear more frequently in North America, Oceania (likely due to Australia), and in Africa. Data, Transparency, and Capacity Issues were also common in North America, Europe, and Oceania. Socioeconomic and Equity Risks were most common in Africa, as well as Direct Anthropogenic Disturbances.

------------------------------------------------------------------------------

### 4.3. Temporal Trends in Permanence Risks
Here I explore temporal trends in the mention of permanence risks. My dataset is skewed to more recent studies published in the last 10 years. Across every time period (5 year intervals), non-physical risks were most common.
```{r}
#| label: temporal-permanence-risks-summary
#| echo: false
#| fig-width: 9
#| fig-height: 6

# Step 0: Set standard domain colors
domain_colors <- c(
  "non-physical" = "#4E79A7",       # Blue
  "physical" = "#59A14F",           # Green
  "methodological" = "#E15759"      # Red
)

# Step 1: Filter and bin data by 5-year intervals (corrected)
final_df_binned <- final_df %>%
  filter(!is.na(permanence_risk_domain), !is.na(study_publication_year)) %>%
  mutate(
    period = cut(
      study_publication_year,
      breaks = c(1990, 1995, 2000, 2005, 2010, 2015, 2020, 2026),
      labels = c("1990–1994", "1995–1999", "2000–2004", "2005–2009", "2010–2014", "2015–2019", "2020–2025"),
      right = FALSE
    )
  )

# Step 2: Summarize the number of distinct studies per period × permanence risk domain
domain_trends_binned <- final_df_binned %>%
  distinct(study_id, period, permanence_risk_domain) %>%
  count(period, permanence_risk_domain, name = "n_studies") %>%
  complete(period, permanence_risk_domain, fill = list(n_studies = 0)) %>%
  filter(!is.na(period))

# Step 3: Plot with standardized domain colors
ggplot(domain_trends_binned, aes(x = period, y = n_studies, fill = permanence_risk_domain)) +
  geom_col(position = "dodge", color = "black") +
  scale_fill_manual(values = domain_colors, name = "Risk Domain") +
  labs(
    title = "Trends in Permanence Risk Domains Over Time",
    x = "Publication Period",
    y = "Number of Studies"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "right"
  )

```

#### 4.3.1. Top 5 Permanence Risks over Time
What were the top 5 permanence risks, and how often do they appear over time?
```{r}
#| label: temporal-top5-risk-types
#| echo: false
#| fig-width: 10
#| fig-height: 6

# Step 1: Identify top 5 most frequently mentioned risk types overall
top_risks_overall <- final_df %>%
  filter(!is.na(permanence_risk_type)) %>%
  distinct(study_id, permanence_risk_type) %>%
  count(permanence_risk_type, sort = TRUE) %>%
  slice_max(n, n = 5) %>%
  pull(permanence_risk_type)

# Step 2: Create yearly trend data for top risks
risk_time_series <- final_df %>%
  filter(permanence_risk_type %in% top_risks_overall, !is.na(study_publication_year)) %>%
  distinct(study_id, study_publication_year, permanence_risk_type) %>%
  count(study_publication_year, permanence_risk_type, name = "n_studies") %>%
  complete(study_publication_year, permanence_risk_type, fill = list(n_studies = 0))

# Step 3: Bin publication years into 5-year intervals
risk_time_series_binned <- risk_time_series %>%
  mutate(period = cut(
    study_publication_year,
    breaks = c(1990, 1995, 2000, 2005, 2010, 2015, 2020, 2026),  # True 5-year bins
    labels = c("1990–1994", "1995–1999", "2000–2004", "2005–2009", "2010–2014", "2015–2019", "2020–2025"),
    right = FALSE
  )) %>%
  group_by(period, permanence_risk_type) %>%
  summarise(n_studies = sum(n_studies), .groups = "drop") %>%
  filter(!is.na(period))

# Optional: Identify which risk types appeared in all time bins
risks_in_bins <- risk_time_series_binned %>%
  filter(n_studies > 0) %>%
  group_by(permanence_risk_type) %>%
  summarise(n_bins = n_distinct(period), .groups = "drop") %>%
  filter(n_bins == 7)

# Step 4: Plot
ggplot(risk_time_series_binned, aes(x = period, y = n_studies, fill = permanence_risk_type)) +
  geom_col(position = "dodge", color = "black") +
  labs(
    title = "Top 5 Permanence Risks Over Time",
    x = "Publication Period",
    y = "Number of Studies",
    fill = "Risk Type"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```
The following risks were mentioned in studies across all six 5-year periods: Limited Data Transparency, Poor Management and Monitoring, and Weak Governance and Enforcement.

##### Top 10 Permanence Risks over Time
Not a very clear figure, but see analysis below.
```{r}
#| label: temporal-top10-risk-types
#| echo: false
#| fig-width: 10
#| fig-height: 6

# Step 1: Identify top 10 most frequently mentioned risk types overall
top_risks_overall <- final_df %>%
  filter(!is.na(permanence_risk_type)) %>%
  distinct(study_id, permanence_risk_type) %>%
  count(permanence_risk_type, sort = TRUE) %>%
  slice_max(n, n = 10) %>%
  pull(permanence_risk_type)

# Step 2: Create yearly trend data for those risks
risk_time_series <- final_df %>%
  filter(permanence_risk_type %in% top_risks_overall, !is.na(study_publication_year)) %>%
  distinct(study_id, study_publication_year, permanence_risk_type) %>%
  count(study_publication_year, permanence_risk_type, name = "n_studies") %>%
  complete(study_publication_year, permanence_risk_type, fill = list(n_studies = 0))

# Step 3: Bin into 5-year intervals
risk_time_series_binned <- risk_time_series %>%
  mutate(period = cut(
    study_publication_year,
    breaks = c(1990, 1995, 2000, 2005, 2010, 2015, 2020, 2026),
    labels = c("1990–1994", "1995–1999", "2000–2004", "2005–2009", "2010–2014", "2015–2019", "2020–2025"),
    right = FALSE
  )) %>%
  group_by(period, permanence_risk_type) %>%
  summarise(n_studies = sum(n_studies), .groups = "drop") %>%
  filter(!is.na(period))

# Step 4: Identify risks that appear in all 7 time bins
risks_in_all_bins <- risk_time_series_binned %>%
  filter(n_studies > 0) %>%
  group_by(permanence_risk_type) %>%
  summarise(n_bins = n_distinct(period), .groups = "drop") %>%
  filter(n_bins == 7)

# Step 5: Identify most common risk type in each time bin
top_risks_by_period <- risk_time_series_binned %>%
  group_by(period) %>%
  slice_max(order_by = n_studies, n = 1, with_ties = FALSE) %>%
  arrange(period)

# Step 6: Plot
ggplot(risk_time_series_binned, aes(x = period, y = n_studies, fill = permanence_risk_type)) +
  geom_col(position = "dodge", color = "black") +
  labs(
    title = "Top 10 Permanence Risks Over Time",
    x = "Publication Period",
    y = "Number of Studies",
    fill = "Risk Type"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "right"
  )

```

```{r}
#| label: top-risk-type-summaries
#| echo: false
#| message: false
#| warning: false

# Step 1: Risks that appeared in all 7 bins
risks_in_all_bins <- risk_time_series_binned %>%
  filter(n_studies > 0) %>%
  group_by(permanence_risk_type) %>%
  summarise(n_bins = n_distinct(period), .groups = "drop") %>%
  filter(n_bins == 7)

# Output human-readable message
if (nrow(risks_in_all_bins) > 0) {
  cat(glue(
    "The following risk types were mentioned in all seven time periods (1990–2025): ",
    paste0(risks_in_all_bins$permanence_risk_type, collapse = ", "), "."
  ))
} else {
  cat("No risk types appeared consistently across all seven time bins.")
}

# Step 2: Most common risk type per bin
top_risks_by_period <- risk_time_series_binned %>%
  group_by(period) %>%
  slice_max(order_by = n_studies, n = 1, with_ties = FALSE) %>%
  arrange(period)

# Output as readable sentences
cat("\n\nMost common risk types per time period:\n")
top_risks_by_period %>%
  mutate(
    sentence = glue("{period}: {permanence_risk_type} (n = {n_studies})")
  ) %>%
  pull(sentence) %>%
  cat(sep = "\n")

```

#### 4.3.2. Temporal Trends in Risks by Program
Here I explore if there are any temporal trends in the risks by program. The 3 most common programs were US CWA 404 Permitting, REDD+, and US Mitigation Banking. Below I compare some of the trends over time between these programs.

##### US Wetland Mitigation Programs
Let's combine the US CWA sec. 404 permitting and mitigation banking programs together and see risks.
```{r}
#| label: temporal-risk-categories-uswetlands-ordered
#| echo: false
#| fig-width: 10
#| fig-height: 6

library(scales)

# Step 1: Bin and group U.S. wetland programs
final_df_binned <- final_df %>%
  filter(!is.na(permanence_risk_category), !is.na(permanence_risk_domain), !is.na(study_publication_year)) %>%
  mutate(
    # Bin publication years with consistent 5-year intervals
    period = cut(
      study_publication_year,
      breaks = c(1990, 1995, 2000, 2005, 2010, 2015, 2020, 2026),
      labels = c("1990–1994", "1995–1999", "2000–2004", "2005–2009", "2010–2014", "2015–2019", "2020–2025"),
      right = FALSE
    ),
    # Combine US wetland-related programs
    program_group = case_when(
      program_name %in% c("US CWA 404 Permitting", "US Mitigation Banking") ~ "US Wetland Programs",
      TRUE ~ program_name
    )
  )

# Step 2: Summarize study counts by risk category (for color ranking)
category_rank <- final_df_binned %>%
  filter(program_group == "US Wetland Programs") %>%
  distinct(study_id, permanence_risk_category, permanence_risk_domain) %>%
  count(permanence_risk_domain, permanence_risk_category, name = "total_n") %>%
  arrange(permanence_risk_domain, desc(total_n)) %>%
  mutate(permanence_risk_category = factor(permanence_risk_category, levels = rev(permanence_risk_category)))

# Step 3: Assign dynamic colors by domain
get_domain_palette <- function(base_color, n) {
  shades <- colorRampPalette(c("white", base_color))(n + 1)[-1]
  rev(shades)
}

domain_colors <- list(
  "non-physical" = get_domain_palette("#4E79A7", 5),
  "physical" = get_domain_palette("#59A14F", 2),
  "methodological" = get_domain_palette("#E15759", 3)
)

# Create category-color mapping
category_colors <- category_rank %>%
  group_by(permanence_risk_domain) %>%
  mutate(color = domain_colors[[unique(permanence_risk_domain)]][seq_len(n())]) %>%
  ungroup() %>%
  select(permanence_risk_category, color) %>%
  deframe()

# Step 4: Prepare data for plotting
risk_cat_binned_uswetlands <- final_df_binned %>%
  filter(program_group == "US Wetland Programs") %>%
  distinct(study_id, period, permanence_risk_category) %>%
  count(period, permanence_risk_category, name = "n_studies") %>%
  complete(period, permanence_risk_category, fill = list(n_studies = 0)) %>%
  filter(!is.na(period)) %>%
  mutate(permanence_risk_category = factor(permanence_risk_category, levels = levels(category_rank$permanence_risk_category)))

# Step 5: Plot
ggplot(risk_cat_binned_uswetlands, aes(x = period, y = n_studies, fill = permanence_risk_category)) +
  geom_col(color = "black") +
  scale_fill_manual(values = category_colors, name = "Risk Category") +
  labs(
    title = "US Wetland Mitigation Programs Risk Categories Over Time",
    x = "Publication Period",
    y = "Number of Studies"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "right",
    legend.title = element_text(size = 11),
    legend.text = element_text(size = 9)
  )
```


Compliance, Legal, and Governance risks are common throughout all periods. Physical risks seem to appear more from 2000 onwards. Data, Transparency, and Capacity issues seem to be common up through 2019 but do not appear in studies from the last 5 years. Ecological Design and Implementation Failures also seem to pop up relatively consistently across most time periods. 

##### REDD+ 
Let's look at REDD+ now.
```{r}
#| label: temporal-risk-categories-redd
#| echo: false
#| fig-width: 10
#| fig-height: 6

library(scales)

# Step 1: Bin years and group REDD+ program
final_df_binned <- final_df %>%
  filter(
    !is.na(permanence_risk_category),
    !is.na(permanence_risk_domain),
    !is.na(study_publication_year),
    program_name == "REDD+"  # Only include REDD+ studies
  ) %>%
  mutate(
    period = cut(
      study_publication_year,
      breaks = c(1990, 1995, 2000, 2005, 2010, 2015, 2020, 2026),  # consistent 5-year bins
      labels = c("1990–1994", "1995–1999", "2000–2004", "2005–2009", "2010–2014", "2015–2019", "2020–2025"),
      right = FALSE
    ),
    program_group = "REDD+"
  )

# Step 2: Rank risk categories within REDD+
category_rank <- final_df_binned %>%
  distinct(study_id, permanence_risk_category, permanence_risk_domain) %>%
  count(permanence_risk_domain, permanence_risk_category, name = "total_n") %>%
  arrange(permanence_risk_domain, desc(total_n)) %>%
  mutate(permanence_risk_category = factor(permanence_risk_category, levels = rev(permanence_risk_category)))

# Step 3: Dynamic color assignment by domain
get_domain_palette <- function(base_color, n) {
  shades <- colorRampPalette(c("white", base_color))(n + 1)[-1]
  rev(shades)
}

domain_colors <- list(
  "non-physical" = get_domain_palette("#4E79A7", 5),
  "physical" = get_domain_palette("#59A14F", 2),
  "methodological" = get_domain_palette("#E15759", 3)
)

# Create category color mapping
category_colors <- category_rank %>%
  group_by(permanence_risk_domain) %>%
  mutate(color = domain_colors[[unique(permanence_risk_domain)]][seq_len(n())]) %>%
  ungroup() %>%
  select(permanence_risk_category, color) %>%
  deframe()

# Step 4: Create final data for plotting
risk_cat_binned_redd <- final_df_binned %>%
  distinct(study_id, period, permanence_risk_category) %>%
  count(period, permanence_risk_category, name = "n_studies") %>%
  complete(period, permanence_risk_category, fill = list(n_studies = 0)) %>%
  filter(!is.na(period)) %>%
  mutate(permanence_risk_category = factor(permanence_risk_category, levels = levels(category_rank$permanence_risk_category)))

# Step 5: Plot stacked bar chart
ggplot(risk_cat_binned_redd, aes(x = period, y = n_studies, fill = permanence_risk_category)) +
  geom_col(color = "black") +
  scale_fill_manual(values = category_colors, name = "Risk Category") +
  labs(
    title = "REDD+ Program Risk Categories Over Time",
    x = "Publication Period",
    y = "Number of Studies"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "right",
    legend.title = element_text(size = 11),
    legend.text = element_text(size = 9)
  )

```

As expected, REDD+ does not appear until the 2005-2009 bin (it was discussed at the 2007 COP). For REDD+, Socioeconomic and Equity Risks and Compliance, Legal, and Governance Risks appear across all time periods. Unlike the US Wetland mitigation programs, Ecological Design and Implementation Failures are completely absent here.

##### What Risks Appeared in US Wetland Mitigation vs REDD+?
```{r}
#| label: compare-risk-categories-redd-wetlands
#| echo: false

# Get unique risk categories for each program
redd_risks <- final_df %>%
  filter(program_name == "REDD+", !is.na(permanence_risk_category)) %>%
  distinct(permanence_risk_category) %>%
  pull()

wetland_risks <- final_df %>%
  filter(program_name %in% c("US CWA 404 Permitting", "US Mitigation Banking"),
         !is.na(permanence_risk_category)) %>%
  distinct(permanence_risk_category) %>%
  pull()

# Compare
only_in_redd <- setdiff(redd_risks, wetland_risks)
only_in_wetlands <- setdiff(wetland_risks, redd_risks)
in_both <- intersect(redd_risks, wetland_risks)

# Output as markdown
cat("**Only in REDD+:**", paste(only_in_redd, collapse = ", "), "\n\n")
cat("**Only in US Wetland Programs:**", paste(only_in_wetlands, collapse = ", "), "\n\n")
cat("**Shared by both:**", paste(in_both, collapse = ", "), "\n")

```

## 5. Summary

Above I explored various facets of the dataset. If I had to summarize some of the key trends I thought were interesting, they would be:

- Non-physical risks were most common overall. These compliance, legal, financial, and institutional risks consistently appear throughout the ~35 year review period. Physical risks, on the other hand, are comparatively underrepresented, despite their potential to destroy physical offset sites. 

- The risk profiles of biodiversity vs carbon offset studies are different, and these vary particularly by geography. Policy non-compliance, limited data transparency, and poor management and monitoring were extremely common risks to biodiversity offset studies, but were very limited in carbon offset studies. On the contrary, land tenure and access conflicts, community exclusion and compensation gaps, and incentive misalignment and opportunity costs were common to carbon offset studies and not biodiversity offset studies.

- I attribute these trends to the geography and program contexts of the studies I reviewed. REDD+ was the most common carbon offset program that appeared, and was often discussed in the context of low- and middle-income countries. Biodiversity offsets were primarily implemented in developed countries and exhibited compliance, legal, and data-related risks, whereas carbon offsets focused more in developing countries and discussed socioeconomic as well as climate-related risks.

- Despite the number of reforms to the U.S. wetland mitigation system (in 2003 and 2008), there does not appear to be a decrease in the number of risks identified. 

(will build this out further with time)










# contintent map

```{r continent-pie-ordered, fig.width=10, fig.height=6, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(colorspace)

# STEP 0: Filter and prepare data --------------------------------------------
continent_df <- final_df %>%
  filter(
    !is.na(study_id),
    !is.na(permanence_risk_category),
    !is.na(permanence_risk_domain),
    !is.na(continent)
  ) %>%
  # Get unique study-category-continent combos
  distinct(study_id, continent, permanence_risk_category, permanence_risk_domain)

# STEP 1: Assign fractional weight per study/continent -----------------------
weighted_df <- continent_df %>%
  group_by(study_id, continent) %>%
  mutate(weight = 1 / n()) %>%
  ungroup()

# STEP 2: Aggregate to get study-weighted counts -----------------------------
continent_risk <- weighted_df %>%
  group_by(continent, permanence_risk_category, permanence_risk_domain) %>%
  summarise(weighted_sum = sum(weight), .groups = "drop")

# STEP 3: Compute percentages per continent ---------------------------------
continent_totals <- continent_risk %>%
  group_by(continent) %>%
  summarise(total_studies = sum(weighted_sum), .groups = "drop")

plot_df <- continent_risk %>%
  left_join(continent_totals, by = "continent") %>%
  mutate(
    percentage = (weighted_sum / total_studies) * 100,
    label = ifelse(percentage >= 5, paste0(round(percentage, 1), "%"), "") # only label slices ≥5%
  )

# STEP 4: Create ordered palette --------------------------------------------
domain_base_colors <- c(
  "physical" = "#59A14F",        # green
  "non-physical" = "#4E79A7",    # blue
  "methodological" = "#E15759"   # red
)

get_domain_palette <- function(base_color, n) {
  colorRampPalette(c("#FFFFFF", base_color))(n + 1)[-1]
}

# Compute base category colors
category_colors_df <- plot_df %>%
  distinct(permanence_risk_category, permanence_risk_domain) %>%
  group_by(permanence_risk_domain) %>%
  arrange(permanence_risk_category) %>%
  mutate(color = get_domain_palette(domain_base_colors[permanence_risk_domain[1]], n())) %>%
  ungroup()

# Compute luminance for dark -> light sorting
rgb_matrix <- hex2RGB(category_colors_df$color)@coords
luminance_vals <- 0.299 * rgb_matrix[, 1] + 0.587 * rgb_matrix[, 2] + 0.114 * rgb_matrix[, 3]

category_colors_df <- category_colors_df %>%
  mutate(luminance = luminance_vals) %>%
  mutate(permanence_risk_domain = factor(permanence_risk_domain, levels = c("physical","non-physical","methodological"))) %>%
  arrange(permanence_risk_domain, luminance)  # dark -> light

# Reorder factor levels and create color vector
ordered_levels <- category_colors_df$permanence_risk_category
category_colors <- setNames(category_colors_df$color, category_colors_df$permanence_risk_category)

plot_df <- plot_df %>%
  mutate(permanence_risk_category = factor(permanence_risk_category, levels = ordered_levels))

# STEP 5: Add facet labels with total studies --------------------------------
facet_labels <- continent_totals %>%
  mutate(facet_label = paste0(continent, " (", round(total_studies), " studies)")) %>%
  select(continent, facet_label)

plot_df <- plot_df %>%
  left_join(facet_labels, by = "continent")

# STEP 6: Plot faceted, ordered pies ----------------------------------------
ggplot(plot_df, aes(x = "", y = percentage, fill = permanence_risk_category)) +
  geom_col(color = "black") +
  geom_text(aes(label = label), position = position_stack(vjust = 0.5), size = 4) +
  coord_polar(theta = "y") +
  facet_wrap(~ facet_label) +
  scale_fill_manual(values = category_colors) +
  labs(
    x = NULL, y = NULL,
    fill = "Risk Category",
    title = "Distribution of Permanence Risk Categories by Continent"
  ) +
  theme_void(base_size = 16) +
  theme(
    legend.position = "bottom",
    legend.title = element_blank(),
    legend.text = element_text(size = 12),
    strip.text = element_text(size = 14, face = "bold"),
    panel.spacing = unit(2, "lines"),
    plot.title = element_text(size = 18, face = "bold", hjust = 0.5)
  )
```

# Run all
```{r}

```

